{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes by Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Tensorflow Version: 1.13.1\n",
      "Tensorflow Probability Version: 0.6.0\n",
      "Found GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tfk.layers \n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "print(\"Tensorflow Version: %s\" % tf.__version__)\n",
    "print(\"Tensorflow Probability Version: %s\" % tfp.__version__)\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('GPU device not found. Using CPU')\n",
    "else:\n",
    "  print('Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'commons' from 'D:\\\\Tom\\\\Documents\\\\gitworkspace\\\\master\\\\ml-probability\\\\tfp_word_embeddings\\\\commons.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commons package\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import commons as cm\n",
    "importlib.reload(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe Configuration\n",
    "\n",
    "# Directory containing the GloVe files.\n",
    "GLOVE_DIR = \"D:/google drive/haw/master/mastertheisis/hauptprojekt\"\n",
    "\n",
    "# Embedding dimension\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = cm.load_imdb()\n",
    "(x_train, y_train), (x_test, y_test) = imdb\n",
    "\n",
    "x_train, y_train, x_test, y_test = (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes by Backprop parameters\n",
    "\n",
    "# model save file\n",
    "model_save_file = \"./models/bayes_by_backprop.h5\"\n",
    "\n",
    "# number of data points\n",
    "N = x_train.shape[0]\n",
    "\n",
    "# hidden layers where each element denotes the number of neurons\n",
    "n_hidden = [32, 32]\n",
    "\n",
    "# batch size for training\n",
    "batch_size = 128\n",
    "\n",
    "# training epochs \n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "17361/88587 unknown words\n"
     ]
    }
   ],
   "source": [
    "# GLOVE Word Embedding\n",
    "word_index = cm.WordIndex()\n",
    "embedding_index = cm.load_glove_embedding(GLOVE_DIR, EMBEDDING_DIM)\n",
    "(embedding_matrix, unknown_words) = word_index.match_glove(embedding_index=embedding_index, embedding_dim=EMBEDDING_DIM)\n",
    "max_length = cm.get_max_length(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad input vectors\n",
    "x_train_padded = cm.pad_input(x_train, max_length)\n",
    "x_test_padded = cm.pad_input(x_test, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has not been trained\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2697, 50)          4429400   \n",
      "_________________________________________________________________\n",
      "dense_flipout_3 (DenseFlipou (None, 2697, 32)          3232      \n",
      "_________________________________________________________________\n",
      "dense_flipout_4 (DenseFlipou (None, 2697, 32)          2080      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86304)             0         \n",
      "_________________________________________________________________\n",
      "dense_flipout_5 (DenseFlipou (None, 1)                 172609    \n",
      "=================================================================\n",
      "Total params: 4,607,321\n",
      "Trainable params: 177,921\n",
      "Non-trainable params: 4,429,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: use DistributionLambda\n",
    "def create_model():\n",
    "    model = tfk.Sequential()\n",
    "    \n",
    "    model.add(tfkl.Embedding(len(word_index.index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_length,\n",
    "                                trainable=False))\n",
    "    \n",
    "    for i in range(len(n_hidden)):\n",
    "        model.add(tfpl.DenseFlipout(n_hidden[i], activation='relu'))\n",
    "        #model.add(tfkl.Dense(n_hidden[i], activation=\"relu\"))\n",
    "    \n",
    "    model.add(tfkl.Flatten())\n",
    "    #model.add(tfkl.Dense(1))\n",
    "    model.add(tfpl.DenseFlipout(1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "try:\n",
    "    model = tfk.models.load_model(model_save_file)\n",
    "    print(\"using saved model\")\n",
    "except:\n",
    "    model = create_model()\n",
    "    print(\"model has not been trained\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 4s 160us/sample - loss: 0.3737 - acc: 0.6977\n",
      "Epoch 2/3\n",
      "  512/25000 [..............................] - ETA: 3s - loss: 0.4173 - acc: 0.6934"
     ]
    }
   ],
   "source": [
    "# https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb\n",
    "\n",
    "loss = lambda y, rv_y: tf.nn.softmax_cross_entropy_with_logits_v2(y, rv_y) # -rv_y.log_prob(y)\n",
    "# negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
    "model.compile(optimizer=tfk.optimizers.Adam(0.0001), loss=loss, metrics=['acc'])\n",
    "model.fit(x_train_padded, y_train, batch_size=batch_size, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25624382]\n",
      " [0.30286568]\n",
      " [0.2687552 ]\n",
      " [0.38936839]\n",
      " [0.40577585]\n",
      " [0.3428033 ]\n",
      " [0.25295734]\n",
      " [0.2931084 ]\n",
      " [0.29015276]\n",
      " [0.29020944]\n",
      " [0.4064741 ]\n",
      " [0.22373727]\n",
      " [0.31555495]\n",
      " [0.3192498 ]\n",
      " [0.30023813]\n",
      " [0.30515906]\n",
      " [0.24586463]\n",
      " [0.39904636]\n",
      " [0.36862183]\n",
      " [0.39201903]\n",
      " [0.21924964]\n",
      " [0.2943172 ]\n",
      " [0.29684055]\n",
      " [0.21511847]\n",
      " [0.2594796 ]\n",
      " [0.2251358 ]\n",
      " [0.31044802]\n",
      " [0.37631226]\n",
      " [0.3618613 ]\n",
      " [0.32714602]\n",
      " [0.22491881]\n",
      " [0.2736989 ]\n",
      " [0.41943216]\n",
      " [0.37304574]\n",
      " [0.21344858]\n",
      " [0.2567035 ]\n",
      " [0.34148777]\n",
      " [0.19696575]\n",
      " [0.19712147]\n",
      " [0.22677389]\n",
      " [0.25840917]\n",
      " [0.21936592]\n",
      " [0.35831112]\n",
      " [0.27102888]\n",
      " [0.29171222]\n",
      " [0.28812498]\n",
      " [0.2855096 ]\n",
      " [0.37459046]\n",
      " [0.33547378]\n",
      " [0.32574177]\n",
      " [0.3508147 ]\n",
      " [0.21291092]\n",
      " [0.30829233]\n",
      " [0.40809423]\n",
      " [0.39123645]\n",
      " [0.19540665]\n",
      " [0.3376423 ]\n",
      " [0.27893275]\n",
      " [0.28532612]\n",
      " [0.29724836]\n",
      " [0.3725403 ]\n",
      " [0.21879518]\n",
      " [0.25331542]\n",
      " [0.3114337 ]\n",
      " [0.31182036]\n",
      " [0.23037186]\n",
      " [0.25508365]\n",
      " [0.16857713]\n",
      " [0.33385536]\n",
      " [0.35125375]\n",
      " [0.28147042]\n",
      " [0.25968498]\n",
      " [0.3058306 ]\n",
      " [0.2296238 ]\n",
      " [0.2985398 ]\n",
      " [0.30642533]\n",
      " [0.3640899 ]\n",
      " [0.3167082 ]\n",
      " [0.31741738]\n",
      " [0.242843  ]\n",
      " [0.4703278 ]\n",
      " [0.25447   ]\n",
      " [0.3425389 ]\n",
      " [0.29318923]\n",
      " [0.3389734 ]\n",
      " [0.2766669 ]\n",
      " [0.2876238 ]\n",
      " [0.30122888]\n",
      " [0.3148049 ]\n",
      " [0.2134881 ]\n",
      " [0.37530518]\n",
      " [0.3329637 ]\n",
      " [0.32893687]\n",
      " [0.32546204]\n",
      " [0.34798074]\n",
      " [0.3364707 ]\n",
      " [0.3646555 ]\n",
      " [0.4532219 ]\n",
      " [0.22011507]\n",
      " [0.22770628]\n",
      " [0.23701537]\n",
      " [0.24370101]\n",
      " [0.30785373]\n",
      " [0.24396276]\n",
      " [0.26038823]\n",
      " [0.25083816]\n",
      " [0.2944253 ]\n",
      " [0.27153498]\n",
      " [0.26444805]\n",
      " [0.3431384 ]\n",
      " [0.31123233]\n",
      " [0.32687145]\n",
      " [0.26033205]\n",
      " [0.25169688]\n",
      " [0.28068894]\n",
      " [0.3207865 ]\n",
      " [0.34120643]\n",
      " [0.25636107]\n",
      " [0.23670036]\n",
      " [0.26921064]\n",
      " [0.31072134]\n",
      " [0.30800936]\n",
      " [0.27002674]\n",
      " [0.3813783 ]\n",
      " [0.2029655 ]\n",
      " [0.22870544]\n",
      " [0.23804015]\n",
      " [0.35818198]]\n",
      "--------------------------------------------------\n",
      "[11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983 11816.983\n",
      " 11816.983 11816.983]\n",
      "[[0.17710483]\n",
      " [0.25246802]\n",
      " [0.23370284]\n",
      " [0.34118247]\n",
      " [0.21179274]\n",
      " [0.26610455]\n",
      " [0.19419602]\n",
      " [0.18945068]\n",
      " [0.25991815]\n",
      " [0.27351844]\n",
      " [0.17444101]\n",
      " [0.27900934]\n",
      " [0.20662177]\n",
      " [0.3147908 ]\n",
      " [0.21315667]\n",
      " [0.28648454]\n",
      " [0.2570929 ]\n",
      " [0.29028028]\n",
      " [0.28383726]\n",
      " [0.2129314 ]\n",
      " [0.167645  ]\n",
      " [0.24261305]\n",
      " [0.29086477]\n",
      " [0.22647294]\n",
      " [0.33067262]\n",
      " [0.21938834]\n",
      " [0.2844473 ]\n",
      " [0.2572912 ]\n",
      " [0.20017996]\n",
      " [0.25929362]\n",
      " [0.34226063]\n",
      " [0.2561695 ]\n",
      " [0.20671007]\n",
      " [0.22837228]\n",
      " [0.4014444 ]\n",
      " [0.23413265]\n",
      " [0.29244062]\n",
      " [0.22260511]\n",
      " [0.23015839]\n",
      " [0.29132718]\n",
      " [0.2638409 ]\n",
      " [0.1658968 ]\n",
      " [0.18279672]\n",
      " [0.17845255]\n",
      " [0.33009928]\n",
      " [0.20227465]\n",
      " [0.2912615 ]\n",
      " [0.28355747]\n",
      " [0.34043032]\n",
      " [0.19629535]\n",
      " [0.24632493]\n",
      " [0.26652765]\n",
      " [0.26933885]\n",
      " [0.2942071 ]\n",
      " [0.28009504]\n",
      " [0.22083938]\n",
      " [0.3010869 ]\n",
      " [0.28552863]\n",
      " [0.3760344 ]\n",
      " [0.272932  ]\n",
      " [0.332632  ]\n",
      " [0.25869113]\n",
      " [0.28435212]\n",
      " [0.29583234]\n",
      " [0.3078082 ]\n",
      " [0.20822743]\n",
      " [0.20999345]\n",
      " [0.28525013]\n",
      " [0.14524764]\n",
      " [0.3494473 ]\n",
      " [0.23575234]\n",
      " [0.27311793]\n",
      " [0.28714773]\n",
      " [0.26248425]\n",
      " [0.17898893]\n",
      " [0.28745252]\n",
      " [0.26090318]\n",
      " [0.23065764]\n",
      " [0.2781577 ]\n",
      " [0.23842731]\n",
      " [0.35456255]\n",
      " [0.32393762]\n",
      " [0.23016593]\n",
      " [0.3364386 ]\n",
      " [0.22093084]\n",
      " [0.24155366]\n",
      " [0.29887253]\n",
      " [0.29313225]\n",
      " [0.22830749]\n",
      " [0.16987944]\n",
      " [0.3067447 ]\n",
      " [0.26419818]\n",
      " [0.3036387 ]\n",
      " [0.37773156]\n",
      " [0.41840905]\n",
      " [0.3349991 ]\n",
      " [0.33505014]\n",
      " [0.32771176]\n",
      " [0.3453865 ]\n",
      " [0.283961  ]\n",
      " [0.3308282 ]\n",
      " [0.25713277]\n",
      " [0.27620485]\n",
      " [0.250469  ]\n",
      " [0.13819465]\n",
      " [0.19585389]\n",
      " [0.27899438]\n",
      " [0.12086093]\n",
      " [0.26634568]\n",
      " [0.23850319]\n",
      " [0.17027774]\n",
      " [0.28981465]\n",
      " [0.24111411]\n",
      " [0.3096211 ]\n",
      " [0.261501  ]\n",
      " [0.30238962]\n",
      " [0.21169975]\n",
      " [0.24638554]\n",
      " [0.25117826]\n",
      " [0.27899116]\n",
      " [0.21468958]\n",
      " [0.53601295]\n",
      " [0.2489526 ]\n",
      " [0.2681839 ]\n",
      " [0.19173843]\n",
      " [0.17750394]\n",
      " [0.16177419]\n",
      " [0.33733085]]\n",
      "[[0.33060187]\n",
      " [0.28979415]\n",
      " [0.25159454]\n",
      " [0.11493745]\n",
      " [0.313903  ]\n",
      " [0.23733023]\n",
      " [0.34163457]\n",
      " [0.3243863 ]\n",
      " [0.22738901]\n",
      " [0.22620556]\n",
      " [0.2399452 ]\n",
      " [0.2685508 ]\n",
      " [0.2350935 ]\n",
      " [0.2403428 ]\n",
      " [0.24513763]\n",
      " [0.24129128]\n",
      " [0.21742573]\n",
      " [0.22798437]\n",
      " [0.23439017]\n",
      " [0.17409593]\n",
      " [0.27687985]\n",
      " [0.18818381]\n",
      " [0.25839615]\n",
      " [0.13946548]\n",
      " [0.24404764]\n",
      " [0.25672418]\n",
      " [0.28978187]\n",
      " [0.19240922]\n",
      " [0.27527726]\n",
      " [0.18340942]\n",
      " [0.21342832]\n",
      " [0.11738613]\n",
      " [0.18119758]\n",
      " [0.20683807]\n",
      " [0.32347497]\n",
      " [0.23772833]\n",
      " [0.21972889]\n",
      " [0.35006848]\n",
      " [0.19353026]\n",
      " [0.28241044]\n",
      " [0.2817222 ]\n",
      " [0.15062433]\n",
      " [0.18825904]\n",
      " [0.19445145]\n",
      " [0.17941236]\n",
      " [0.2375027 ]\n",
      " [0.21959797]\n",
      " [0.26730096]\n",
      " [0.30368197]\n",
      " [0.33043006]\n",
      " [0.34711546]\n",
      " [0.11239642]\n",
      " [0.22641093]\n",
      " [0.24127373]\n",
      " [0.29519823]\n",
      " [0.25176287]\n",
      " [0.22525388]\n",
      " [0.20183834]\n",
      " [0.21646231]\n",
      " [0.23213935]\n",
      " [0.23558813]\n",
      " [0.23025167]\n",
      " [0.1916824 ]\n",
      " [0.3097685 ]\n",
      " [0.34731525]\n",
      " [0.18896013]\n",
      " [0.22199994]\n",
      " [0.33919653]\n",
      " [0.27134764]\n",
      " [0.2638119 ]\n",
      " [0.32561192]\n",
      " [0.2174297 ]\n",
      " [0.25525373]\n",
      " [0.24151057]\n",
      " [0.21044558]\n",
      " [0.27444726]\n",
      " [0.22506362]\n",
      " [0.22285011]\n",
      " [0.34655568]\n",
      " [0.20964238]\n",
      " [0.2589553 ]\n",
      " [0.27328438]\n",
      " [0.30180246]\n",
      " [0.18392402]\n",
      " [0.25754026]\n",
      " [0.21131682]\n",
      " [0.28980142]\n",
      " [0.3020838 ]\n",
      " [0.24305257]\n",
      " [0.27358955]\n",
      " [0.20510316]\n",
      " [0.2453652 ]\n",
      " [0.1841439 ]\n",
      " [0.25075203]\n",
      " [0.25615633]\n",
      " [0.167214  ]\n",
      " [0.21744502]\n",
      " [0.39348736]\n",
      " [0.21554884]\n",
      " [0.2611553 ]\n",
      " [0.21777397]\n",
      " [0.2919792 ]\n",
      " [0.31465632]\n",
      " [0.20584533]\n",
      " [0.3161283 ]\n",
      " [0.35205168]\n",
      " [0.1434558 ]\n",
      " [0.27700403]\n",
      " [0.20329416]\n",
      " [0.28263193]\n",
      " [0.25953203]\n",
      " [0.19792983]\n",
      " [0.3442864 ]\n",
      " [0.15276372]\n",
      " [0.20800155]\n",
      " [0.22035667]\n",
      " [0.21558979]\n",
      " [0.3165046 ]\n",
      " [0.29708737]\n",
      " [0.2412529 ]\n",
      " [0.2311013 ]\n",
      " [0.2561195 ]\n",
      " [0.22541657]\n",
      " [0.21448079]\n",
      " [0.19603294]\n",
      " [0.24798548]\n",
      " [0.2216618 ]\n",
      " [0.2194243 ]]\n",
      "--------------------------------------------------\n",
      "[11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175 11807.175\n",
      " 11807.175 11807.175]\n",
      "[[0.2337099 ]\n",
      " [0.13988557]\n",
      " [0.29481232]\n",
      " [0.2254011 ]\n",
      " [0.1763736 ]\n",
      " [0.26090127]\n",
      " [0.30247182]\n",
      " [0.22978976]\n",
      " [0.26900876]\n",
      " [0.1709854 ]\n",
      " [0.2340905 ]\n",
      " [0.17858687]\n",
      " [0.18322629]\n",
      " [0.16762641]\n",
      " [0.335675  ]\n",
      " [0.17250869]\n",
      " [0.2556916 ]\n",
      " [0.20582065]\n",
      " [0.28757346]\n",
      " [0.30109212]\n",
      " [0.17347673]\n",
      " [0.14961267]\n",
      " [0.24078941]\n",
      " [0.26298583]\n",
      " [0.12748104]\n",
      " [0.17902854]\n",
      " [0.24739414]\n",
      " [0.26336634]\n",
      " [0.1868307 ]\n",
      " [0.35471857]\n",
      " [0.2629701 ]\n",
      " [0.22742632]\n",
      " [0.19512242]\n",
      " [0.23858553]\n",
      " [0.2595014 ]\n",
      " [0.18514305]\n",
      " [0.16619542]\n",
      " [0.16529539]\n",
      " [0.18869919]\n",
      " [0.19894779]\n",
      " [0.18966293]\n",
      " [0.29053646]\n",
      " [0.26195475]\n",
      " [0.15328512]\n",
      " [0.26535177]\n",
      " [0.23096687]\n",
      " [0.2332173 ]\n",
      " [0.11468309]\n",
      " [0.3085152 ]\n",
      " [0.29203916]\n",
      " [0.11983845]\n",
      " [0.23797613]\n",
      " [0.17100248]\n",
      " [0.23657337]\n",
      " [0.1526879 ]\n",
      " [0.22032061]\n",
      " [0.3806189 ]\n",
      " [0.35739505]\n",
      " [0.15945819]\n",
      " [0.18988243]\n",
      " [0.16937166]\n",
      " [0.23234063]\n",
      " [0.25042924]\n",
      " [0.18867871]\n",
      " [0.26729572]\n",
      " [0.25552452]\n",
      " [0.1528059 ]\n",
      " [0.24915001]\n",
      " [0.21655959]\n",
      " [0.29538715]\n",
      " [0.16871971]\n",
      " [0.2524137 ]\n",
      " [0.22306049]\n",
      " [0.14705703]\n",
      " [0.20762983]\n",
      " [0.19363275]\n",
      " [0.20988932]\n",
      " [0.20411476]\n",
      " [0.26794675]\n",
      " [0.19038475]\n",
      " [0.19984165]\n",
      " [0.19854036]\n",
      " [0.28789777]\n",
      " [0.16452208]\n",
      " [0.23180753]\n",
      " [0.22462034]\n",
      " [0.2145356 ]\n",
      " [0.21215546]\n",
      " [0.3162195 ]\n",
      " [0.14827493]\n",
      " [0.25951368]\n",
      " [0.27909386]\n",
      " [0.1836454 ]\n",
      " [0.20267239]\n",
      " [0.19735861]\n",
      " [0.2008976 ]\n",
      " [0.2650049 ]\n",
      " [0.35547101]\n",
      " [0.34234732]\n",
      " [0.3012939 ]\n",
      " [0.266707  ]\n",
      " [0.26438746]\n",
      " [0.21687946]\n",
      " [0.3057593 ]\n",
      " [0.35307977]\n",
      " [0.22088334]\n",
      " [0.21537739]\n",
      " [0.20095009]\n",
      " [0.15098852]\n",
      " [0.21945482]\n",
      " [0.21441942]\n",
      " [0.22156852]\n",
      " [0.16182521]\n",
      " [0.23726097]\n",
      " [0.19055775]\n",
      " [0.21028638]\n",
      " [0.2955459 ]\n",
      " [0.18497694]\n",
      " [0.24243116]\n",
      " [0.3506704 ]\n",
      " [0.23058748]\n",
      " [0.22972858]\n",
      " [0.26038605]\n",
      " [0.19142169]\n",
      " [0.34266263]\n",
      " [0.2057749 ]\n",
      " [0.2492505 ]\n",
      " [0.24088836]]\n",
      "[[0.2194128 ]\n",
      " [0.16571954]\n",
      " [0.1218569 ]\n",
      " [0.19257647]\n",
      " [0.26498252]\n",
      " [0.19695383]\n",
      " [0.2829988 ]\n",
      " [0.16386336]\n",
      " [0.17492825]\n",
      " [0.14171264]\n",
      " [0.17491472]\n",
      " [0.3334575 ]\n",
      " [0.166152  ]\n",
      " [0.17074373]\n",
      " [0.20736817]\n",
      " [0.24982989]\n",
      " [0.15333861]\n",
      " [0.25662524]\n",
      " [0.28101176]\n",
      " [0.33335778]\n",
      " [0.22112069]\n",
      " [0.19464222]\n",
      " [0.12646782]\n",
      " [0.19725543]\n",
      " [0.12843424]\n",
      " [0.22656858]\n",
      " [0.18294099]\n",
      " [0.24563047]\n",
      " [0.28300178]\n",
      " [0.15958288]\n",
      " [0.18834665]\n",
      " [0.23331475]\n",
      " [0.22189182]\n",
      " [0.212672  ]\n",
      " [0.23487729]\n",
      " [0.13244426]\n",
      " [0.21293142]\n",
      " [0.32346532]\n",
      " [0.2854272 ]\n",
      " [0.20060605]\n",
      " [0.23102513]\n",
      " [0.18505275]\n",
      " [0.19075853]\n",
      " [0.22200945]\n",
      " [0.18880877]\n",
      " [0.2537192 ]\n",
      " [0.18413684]\n",
      " [0.17681128]\n",
      " [0.169967  ]\n",
      " [0.29157296]\n",
      " [0.20658514]\n",
      " [0.20442542]\n",
      " [0.22488949]\n",
      " [0.24907264]\n",
      " [0.16815814]\n",
      " [0.19272557]\n",
      " [0.13360035]\n",
      " [0.18702322]\n",
      " [0.28292805]\n",
      " [0.19008037]\n",
      " [0.1714223 ]\n",
      " [0.22365636]\n",
      " [0.21396697]\n",
      " [0.22293738]\n",
      " [0.1841419 ]\n",
      " [0.19068953]\n",
      " [0.26507288]\n",
      " [0.16147557]\n",
      " [0.22349218]\n",
      " [0.16674766]\n",
      " [0.18188739]\n",
      " [0.1950014 ]\n",
      " [0.18926054]\n",
      " [0.24955562]\n",
      " [0.26633114]\n",
      " [0.14374545]\n",
      " [0.1804198 ]\n",
      " [0.21379685]\n",
      " [0.18249872]\n",
      " [0.24346519]\n",
      " [0.24144676]\n",
      " [0.09982145]\n",
      " [0.1629036 ]\n",
      " [0.19353235]\n",
      " [0.14490277]\n",
      " [0.3087901 ]\n",
      " [0.18629089]\n",
      " [0.15903836]\n",
      " [0.21261859]\n",
      " [0.21225968]\n",
      " [0.21801719]\n",
      " [0.21609074]\n",
      " [0.15023085]\n",
      " [0.1716111 ]\n",
      " [0.22143447]\n",
      " [0.21596149]\n",
      " [0.20864344]\n",
      " [0.2434029 ]\n",
      " [0.21670783]\n",
      " [0.1663864 ]\n",
      " [0.21691456]\n",
      " [0.21451247]\n",
      " [0.18456894]\n",
      " [0.18309924]\n",
      " [0.29803503]\n",
      " [0.18645945]\n",
      " [0.25988954]\n",
      " [0.17823437]\n",
      " [0.23519507]\n",
      " [0.2520746 ]\n",
      " [0.24735212]\n",
      " [0.1819025 ]\n",
      " [0.2633657 ]\n",
      " [0.15710986]\n",
      " [0.18448126]\n",
      " [0.23785594]\n",
      " [0.19932395]\n",
      " [0.2542945 ]\n",
      " [0.3227444 ]\n",
      " [0.14340279]\n",
      " [0.21917805]\n",
      " [0.24233687]\n",
      " [0.3119973 ]\n",
      " [0.2221249 ]\n",
      " [0.24544433]\n",
      " [0.22076404]\n",
      " [0.1664558 ]\n",
      " [0.16004121]]\n",
      "--------------------------------------------------\n",
      "[11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382 11797.382\n",
      " 11797.382 11797.382]\n",
      "[[0.3078759 ]\n",
      " [0.13072416]\n",
      " [0.22945637]\n",
      " [0.20976982]\n",
      " [0.13192976]\n",
      " [0.27387238]\n",
      " [0.22330704]\n",
      " [0.19128701]\n",
      " [0.1998151 ]\n",
      " [0.17693502]\n",
      " [0.15311015]\n",
      " [0.2522528 ]\n",
      " [0.15321213]\n",
      " [0.21601325]\n",
      " [0.23014656]\n",
      " [0.17438453]\n",
      " [0.20640957]\n",
      " [0.19157717]\n",
      " [0.19583946]\n",
      " [0.20782417]\n",
      " [0.23373303]\n",
      " [0.19408241]\n",
      " [0.20536634]\n",
      " [0.2312516 ]\n",
      " [0.17443171]\n",
      " [0.14752549]\n",
      " [0.23217613]\n",
      " [0.1421915 ]\n",
      " [0.1374968 ]\n",
      " [0.21392089]\n",
      " [0.17971176]\n",
      " [0.17140338]\n",
      " [0.20490763]\n",
      " [0.19717848]\n",
      " [0.15676877]\n",
      " [0.24182579]\n",
      " [0.22833651]\n",
      " [0.2685079 ]\n",
      " [0.15113068]\n",
      " [0.2393426 ]\n",
      " [0.20329136]\n",
      " [0.20369756]\n",
      " [0.29854006]\n",
      " [0.20438597]\n",
      " [0.14586225]\n",
      " [0.16820109]\n",
      " [0.19150433]\n",
      " [0.1787591 ]\n",
      " [0.22814658]\n",
      " [0.20436463]\n",
      " [0.29741746]\n",
      " [0.17023379]\n",
      " [0.1668359 ]\n",
      " [0.11001915]\n",
      " [0.18894571]\n",
      " [0.24331972]\n",
      " [0.2974795 ]\n",
      " [0.1656639 ]\n",
      " [0.18227929]\n",
      " [0.22923857]\n",
      " [0.1761069 ]\n",
      " [0.22093946]\n",
      " [0.18185252]\n",
      " [0.15967175]\n",
      " [0.17584956]\n",
      " [0.18091223]\n",
      " [0.2016117 ]\n",
      " [0.163241  ]\n",
      " [0.20312887]\n",
      " [0.27435717]\n",
      " [0.14174765]\n",
      " [0.21911755]\n",
      " [0.1712524 ]\n",
      " [0.1986121 ]\n",
      " [0.2213375 ]\n",
      " [0.27449492]\n",
      " [0.12281507]\n",
      " [0.12635532]\n",
      " [0.19144318]\n",
      " [0.20533633]\n",
      " [0.16147968]\n",
      " [0.13329545]\n",
      " [0.24379882]\n",
      " [0.2313092 ]\n",
      " [0.1590266 ]\n",
      " [0.13204879]\n",
      " [0.22215506]\n",
      " [0.20855245]\n",
      " [0.13460287]\n",
      " [0.19387153]\n",
      " [0.13677105]\n",
      " [0.2116425 ]\n",
      " [0.22078559]\n",
      " [0.21781641]\n",
      " [0.22271779]\n",
      " [0.28004077]\n",
      " [0.1304391 ]\n",
      " [0.28839403]\n",
      " [0.1613766 ]\n",
      " [0.1836516 ]\n",
      " [0.1919584 ]\n",
      " [0.19804022]\n",
      " [0.16624898]\n",
      " [0.18304855]\n",
      " [0.1844064 ]\n",
      " [0.2457672 ]\n",
      " [0.20921224]\n",
      " [0.19212896]\n",
      " [0.22103333]\n",
      " [0.18444663]\n",
      " [0.20513365]\n",
      " [0.2712369 ]\n",
      " [0.19839188]\n",
      " [0.20438361]\n",
      " [0.24178338]\n",
      " [0.19614547]\n",
      " [0.14529684]\n",
      " [0.2006214 ]\n",
      " [0.3272357 ]\n",
      " [0.2050268 ]\n",
      " [0.18099341]\n",
      " [0.21278223]\n",
      " [0.13648659]\n",
      " [0.31391332]\n",
      " [0.20417604]\n",
      " [0.18007046]\n",
      " [0.19646066]\n",
      " [0.17637143]]\n",
      "[[0.13882259]\n",
      " [0.19166356]\n",
      " [0.20756304]\n",
      " [0.2163282 ]\n",
      " [0.20747343]\n",
      " [0.17647573]\n",
      " [0.11852726]\n",
      " [0.26184252]\n",
      " [0.16082686]\n",
      " [0.209476  ]\n",
      " [0.17204672]\n",
      " [0.15479487]\n",
      " [0.14724219]\n",
      " [0.22009116]\n",
      " [0.21158433]\n",
      " [0.16897553]\n",
      " [0.20079693]\n",
      " [0.17338815]\n",
      " [0.20768037]\n",
      " [0.1467795 ]\n",
      " [0.20251065]\n",
      " [0.26485115]\n",
      " [0.10771793]\n",
      " [0.17849863]\n",
      " [0.17757264]\n",
      " [0.12177512]\n",
      " [0.3002051 ]\n",
      " [0.21284866]\n",
      " [0.16209546]\n",
      " [0.25629908]\n",
      " [0.13854775]\n",
      " [0.19828671]\n",
      " [0.34705943]\n",
      " [0.2670768 ]\n",
      " [0.1477116 ]\n",
      " [0.17244276]\n",
      " [0.1679852 ]\n",
      " [0.09882572]\n",
      " [0.16452879]\n",
      " [0.22510138]\n",
      " [0.25301474]\n",
      " [0.07285905]\n",
      " [0.19625613]\n",
      " [0.16779032]\n",
      " [0.2523122 ]\n",
      " [0.14219677]\n",
      " [0.2263267 ]\n",
      " [0.17022544]\n",
      " [0.22935697]\n",
      " [0.21266747]\n",
      " [0.14891669]\n",
      " [0.16786614]\n",
      " [0.1773803 ]\n",
      " [0.18522161]\n",
      " [0.18253744]\n",
      " [0.25093085]\n",
      " [0.1876958 ]\n",
      " [0.20634347]\n",
      " [0.10005116]\n",
      " [0.13240445]\n",
      " [0.1826747 ]\n",
      " [0.24106744]\n",
      " [0.1319364 ]\n",
      " [0.15048054]\n",
      " [0.21321583]\n",
      " [0.16805926]\n",
      " [0.15952462]\n",
      " [0.17743823]\n",
      " [0.2416347 ]\n",
      " [0.20099571]\n",
      " [0.10538808]\n",
      " [0.14954305]\n",
      " [0.24091017]\n",
      " [0.16246402]\n",
      " [0.23904198]\n",
      " [0.12832028]\n",
      " [0.23062173]\n",
      " [0.16310528]\n",
      " [0.21759507]\n",
      " [0.13280937]\n",
      " [0.26575616]\n",
      " [0.3392088 ]\n",
      " [0.24698102]\n",
      " [0.15144798]\n",
      " [0.18808964]\n",
      " [0.18304577]\n",
      " [0.13507676]\n",
      " [0.19224042]\n",
      " [0.17501095]\n",
      " [0.18524918]\n",
      " [0.15755033]\n",
      " [0.18294424]\n",
      " [0.25609487]\n",
      " [0.2002961 ]\n",
      " [0.16086635]\n",
      " [0.12554717]\n",
      " [0.15675327]\n",
      " [0.16357875]\n",
      " [0.20753077]\n",
      " [0.15824896]\n",
      " [0.12916955]\n",
      " [0.17791319]\n",
      " [0.1949805 ]\n",
      " [0.13735822]\n",
      " [0.15938187]\n",
      " [0.13872615]\n",
      " [0.21830383]\n",
      " [0.17999962]\n",
      " [0.16796964]\n",
      " [0.21142802]\n",
      " [0.14013302]\n",
      " [0.164817  ]\n",
      " [0.14359388]\n",
      " [0.16855928]\n",
      " [0.17426679]\n",
      " [0.19879946]\n",
      " [0.24050215]\n",
      " [0.20799094]\n",
      " [0.1722205 ]\n",
      " [0.20988858]\n",
      " [0.14080608]\n",
      " [0.15463272]\n",
      " [0.1541011 ]\n",
      " [0.12845206]\n",
      " [0.1947129 ]\n",
      " [0.17171216]\n",
      " [0.19262627]\n",
      " [0.19384375]]\n",
      "--------------------------------------------------\n",
      "[11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608 11787.608\n",
      " 11787.608 11787.608]\n",
      "[[0.13452399]\n",
      " [0.16644907]\n",
      " [0.21745333]\n",
      " [0.11890817]\n",
      " [0.05864918]\n",
      " [0.2031965 ]\n",
      " [0.10653555]\n",
      " [0.21871051]\n",
      " [0.22922796]\n",
      " [0.17811248]\n",
      " [0.11059242]\n",
      " [0.22870108]\n",
      " [0.16871864]\n",
      " [0.15198383]\n",
      " [0.18543062]\n",
      " [0.27863458]\n",
      " [0.21510136]\n",
      " [0.15811491]\n",
      " [0.1024909 ]\n",
      " [0.18292418]\n",
      " [0.14583364]\n",
      " [0.19634807]\n",
      " [0.12443748]\n",
      " [0.18424067]\n",
      " [0.18894249]\n",
      " [0.1720447 ]\n",
      " [0.168414  ]\n",
      " [0.09163779]\n",
      " [0.10073772]\n",
      " [0.11630145]\n",
      " [0.18511724]\n",
      " [0.10681024]\n",
      " [0.18909454]\n",
      " [0.17684862]\n",
      " [0.20815828]\n",
      " [0.09193683]\n",
      " [0.19384778]\n",
      " [0.29791605]\n",
      " [0.16888642]\n",
      " [0.2019951 ]\n",
      " [0.22746587]\n",
      " [0.17995754]\n",
      " [0.14657447]\n",
      " [0.176619  ]\n",
      " [0.15995824]\n",
      " [0.23823124]\n",
      " [0.21792209]\n",
      " [0.08422974]\n",
      " [0.12408453]\n",
      " [0.23255628]\n",
      " [0.17094219]\n",
      " [0.13988096]\n",
      " [0.10786498]\n",
      " [0.14824247]\n",
      " [0.14262468]\n",
      " [0.2033014 ]\n",
      " [0.14836115]\n",
      " [0.13117167]\n",
      " [0.10511038]\n",
      " [0.1541037 ]\n",
      " [0.15887147]\n",
      " [0.225492  ]\n",
      " [0.14818761]\n",
      " [0.16655761]\n",
      " [0.18448743]\n",
      " [0.13401887]\n",
      " [0.2007184 ]\n",
      " [0.20974007]\n",
      " [0.15346047]\n",
      " [0.13387403]\n",
      " [0.16020638]\n",
      " [0.08763182]\n",
      " [0.18911573]\n",
      " [0.1983214 ]\n",
      " [0.20233059]\n",
      " [0.20949167]\n",
      " [0.13954192]\n",
      " [0.21267027]\n",
      " [0.18396321]\n",
      " [0.14887989]\n",
      " [0.12683707]\n",
      " [0.20193824]\n",
      " [0.21853179]\n",
      " [0.11378199]\n",
      " [0.16488016]\n",
      " [0.2182053 ]\n",
      " [0.14364779]\n",
      " [0.16090184]\n",
      " [0.20003515]\n",
      " [0.1583809 ]\n",
      " [0.15127799]\n",
      " [0.1344428 ]\n",
      " [0.14116576]\n",
      " [0.18701974]\n",
      " [0.18512875]\n",
      " [0.20715585]\n",
      " [0.1474221 ]\n",
      " [0.13480306]\n",
      " [0.1673159 ]\n",
      " [0.3449182 ]\n",
      " [0.18765575]\n",
      " [0.2952479 ]\n",
      " [0.17213455]\n",
      " [0.23433581]\n",
      " [0.15889874]\n",
      " [0.15728444]\n",
      " [0.17889541]\n",
      " [0.2042149 ]\n",
      " [0.20113727]\n",
      " [0.19520265]\n",
      " [0.14682007]\n",
      " [0.17229116]\n",
      " [0.12518018]\n",
      " [0.19947255]\n",
      " [0.18796438]\n",
      " [0.15060505]\n",
      " [0.18313545]\n",
      " [0.11175224]\n",
      " [0.11542287]\n",
      " [0.19845092]\n",
      " [0.18584445]\n",
      " [0.16502276]\n",
      " [0.1568512 ]\n",
      " [0.21168807]\n",
      " [0.19161624]\n",
      " [0.12978807]\n",
      " [0.19432375]\n",
      " [0.13488853]]\n",
      "[[0.22348213]\n",
      " [0.19753316]\n",
      " [0.15767193]\n",
      " [0.16166815]\n",
      " [0.18504485]\n",
      " [0.15579578]\n",
      " [0.13793   ]\n",
      " [0.17413622]\n",
      " [0.14703816]\n",
      " [0.13223147]\n",
      " [0.08200017]\n",
      " [0.31190497]\n",
      " [0.1542722 ]\n",
      " [0.14194062]\n",
      " [0.21905693]\n",
      " [0.09409159]\n",
      " [0.14524657]\n",
      " [0.22305143]\n",
      " [0.11603504]\n",
      " [0.239286  ]\n",
      " [0.18468636]\n",
      " [0.15018892]\n",
      " [0.13067651]\n",
      " [0.14618722]\n",
      " [0.20366246]\n",
      " [0.25350857]\n",
      " [0.1517834 ]\n",
      " [0.18683442]\n",
      " [0.14360881]\n",
      " [0.1593374 ]\n",
      " [0.12955916]\n",
      " [0.10000128]\n",
      " [0.09808078]\n",
      " [0.09985387]\n",
      " [0.10053146]\n",
      " [0.20122963]\n",
      " [0.11745414]\n",
      " [0.1615237 ]\n",
      " [0.14167401]\n",
      " [0.2076895 ]\n",
      " [0.15469515]\n",
      " [0.13663656]\n",
      " [0.14115614]\n",
      " [0.11873269]\n",
      " [0.21658522]\n",
      " [0.17145917]\n",
      " [0.13501087]\n",
      " [0.17822379]\n",
      " [0.1502355 ]\n",
      " [0.12455109]\n",
      " [0.14325514]\n",
      " [0.16133252]\n",
      " [0.10030764]\n",
      " [0.14468533]\n",
      " [0.15419412]\n",
      " [0.12965202]\n",
      " [0.19579235]\n",
      " [0.12607133]\n",
      " [0.16460729]\n",
      " [0.17367256]\n",
      " [0.10657293]\n",
      " [0.15194494]\n",
      " [0.15217003]\n",
      " [0.12090731]\n",
      " [0.21135244]\n",
      " [0.27397645]\n",
      " [0.08885109]\n",
      " [0.08973864]\n",
      " [0.14178202]\n",
      " [0.21666709]\n",
      " [0.18390733]\n",
      " [0.13994902]\n",
      " [0.09247935]\n",
      " [0.21176723]\n",
      " [0.15771043]\n",
      " [0.19667551]\n",
      " [0.12909144]\n",
      " [0.13591346]\n",
      " [0.18991229]\n",
      " [0.1347599 ]\n",
      " [0.23736584]\n",
      " [0.17071223]\n",
      " [0.09582725]\n",
      " [0.23370239]\n",
      " [0.12119368]\n",
      " [0.13396701]\n",
      " [0.15039763]\n",
      " [0.16321594]\n",
      " [0.20989397]\n",
      " [0.18345878]\n",
      " [0.11482984]\n",
      " [0.11172071]\n",
      " [0.18063676]\n",
      " [0.09246683]\n",
      " [0.15801561]\n",
      " [0.11546102]\n",
      " [0.22470993]\n",
      " [0.13674426]\n",
      " [0.08270827]\n",
      " [0.14875227]\n",
      " [0.14397034]\n",
      " [0.15029678]\n",
      " [0.14735523]\n",
      " [0.098171  ]\n",
      " [0.1781247 ]\n",
      " [0.21534514]\n",
      " [0.14195272]\n",
      " [0.18024695]\n",
      " [0.20405349]\n",
      " [0.1866613 ]\n",
      " [0.16161811]\n",
      " [0.18939334]\n",
      " [0.14762703]\n",
      " [0.22332749]\n",
      " [0.19702503]\n",
      " [0.18246305]\n",
      " [0.15756309]\n",
      " [0.18616742]\n",
      " [0.1271596 ]\n",
      " [0.14552462]\n",
      " [0.11001959]\n",
      " [0.17344844]\n",
      " [0.21007842]\n",
      " [0.18470281]\n",
      " [0.19318902]\n",
      " [0.1400443 ]\n",
      " [0.14479524]\n",
      " [0.26245162]]\n",
      "--------------------------------------------------\n",
      "[11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853 11777.853\n",
      " 11777.853 11777.853]\n",
      "[[0.14933833]\n",
      " [0.25308064]\n",
      " [0.17203942]\n",
      " [0.22370383]\n",
      " [0.11077636]\n",
      " [0.11329225]\n",
      " [0.1417968 ]\n",
      " [0.16060838]\n",
      " [0.1413446 ]\n",
      " [0.11869419]\n",
      " [0.15383473]\n",
      " [0.18402952]\n",
      " [0.08820996]\n",
      " [0.19065645]\n",
      " [0.10569459]\n",
      " [0.15740064]\n",
      " [0.13118955]\n",
      " [0.14459443]\n",
      " [0.15063879]\n",
      " [0.13503748]\n",
      " [0.1945175 ]\n",
      " [0.1822097 ]\n",
      " [0.12744164]\n",
      " [0.14010373]\n",
      " [0.10313669]\n",
      " [0.09793016]\n",
      " [0.17957747]\n",
      " [0.16934231]\n",
      " [0.13278902]\n",
      " [0.09071365]\n",
      " [0.16578272]\n",
      " [0.14000985]\n",
      " [0.14132571]\n",
      " [0.20564228]\n",
      " [0.21858916]\n",
      " [0.14910781]\n",
      " [0.11454636]\n",
      " [0.13702616]\n",
      " [0.15975767]\n",
      " [0.14017889]\n",
      " [0.07503724]\n",
      " [0.17030364]\n",
      " [0.20562825]\n",
      " [0.11757353]\n",
      " [0.12816402]\n",
      " [0.20311716]\n",
      " [0.09854361]\n",
      " [0.16111204]\n",
      " [0.13126495]\n",
      " [0.08654919]\n",
      " [0.19862396]\n",
      " [0.11937472]\n",
      " [0.20581165]\n",
      " [0.13712177]\n",
      " [0.13209069]\n",
      " [0.12349775]\n",
      " [0.14318818]\n",
      " [0.15444252]\n",
      " [0.13545227]\n",
      " [0.14903298]\n",
      " [0.10727227]\n",
      " [0.11839041]\n",
      " [0.12707192]\n",
      " [0.10395664]\n",
      " [0.14554971]\n",
      " [0.08847511]\n",
      " [0.26508564]\n",
      " [0.13331705]\n",
      " [0.10870692]\n",
      " [0.14838514]\n",
      " [0.23074251]\n",
      " [0.16335803]\n",
      " [0.16479325]\n",
      " [0.13981596]\n",
      " [0.1995225 ]\n",
      " [0.11625898]\n",
      " [0.1897904 ]\n",
      " [0.21030298]\n",
      " [0.12707072]\n",
      " [0.20915878]\n",
      " [0.13617808]\n",
      " [0.08686608]\n",
      " [0.11491352]\n",
      " [0.13256532]\n",
      " [0.14992931]\n",
      " [0.11970165]\n",
      " [0.12023041]\n",
      " [0.1352177 ]\n",
      " [0.12582862]\n",
      " [0.183303  ]\n",
      " [0.1480979 ]\n",
      " [0.12667823]\n",
      " [0.09478083]\n",
      " [0.10440499]\n",
      " [0.10686186]\n",
      " [0.17028576]\n",
      " [0.09986764]\n",
      " [0.11368543]\n",
      " [0.10927823]\n",
      " [0.19809306]\n",
      " [0.24840498]\n",
      " [0.11193702]\n",
      " [0.12711918]\n",
      " [0.12093455]\n",
      " [0.14157286]\n",
      " [0.13144118]\n",
      " [0.11959854]\n",
      " [0.22008207]\n",
      " [0.08261582]\n",
      " [0.21504802]\n",
      " [0.22266325]\n",
      " [0.15761107]\n",
      " [0.16444978]\n",
      " [0.17640182]\n",
      " [0.11833969]\n",
      " [0.1350509 ]\n",
      " [0.31054148]\n",
      " [0.25035363]\n",
      " [0.09668383]\n",
      " [0.12259352]\n",
      " [0.22305349]\n",
      " [0.153445  ]\n",
      " [0.12439999]\n",
      " [0.16077253]\n",
      " [0.14485964]\n",
      " [0.10652789]\n",
      " [0.16627109]\n",
      " [0.1367707 ]]\n"
     ]
    }
   ],
   "source": [
    "# https://qiita.com/takeshikondo/items/46659a120f0af7ec2cca\n",
    "\n",
    "x = tf.placeholder(shape=x_train_padded.shape, dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size, 1), dtype=tf.int32)\n",
    "\n",
    "x_test_tf = tf.placeholder(shape=x_train_padded.shape, dtype=tf.float32)\n",
    "\n",
    "logits = model(x)\n",
    "neg_log_likelihood = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=y, logits=logits)\n",
    "kl = tf.reduce_mean(model.losses)\n",
    "elbo_loss = neg_log_likelihood + kl\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(elbo_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        yyy = sess.run(tf.expand_dims(y_train, 1))\n",
    "        feed_dict = {\n",
    "            x: x_train_padded, \n",
    "            y: yyy\n",
    "        }\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "        loss_train = sess.run(elbo_loss, feed_dict=feed_dict)\n",
    "        #acc_train = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        \n",
    "        # sess.run(model(x_test_tf), feed_dict={x_test_tf: x_test_padded}) \n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print ('-' * 50)\n",
    "            print(loss_train)\n",
    "            #print ('Step: {:>3d} Loss: {:.3f}'.format(epoch + 1, loss_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.dtype' object has no attribute 'base_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-3c344a05e493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Eager execution on data tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    813\u001b[0m     outputs, _ = self._run_internal_graph(inputs,\n\u001b[0;32m    814\u001b[0m                                           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m                                           mask=masks)\n\u001b[0m\u001b[0;32m    816\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                   \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                   \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'compute_mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                   output_masks = layer.compute_mask(computed_tensor,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'int32'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mdtype\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1013\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m   \"\"\"\n\u001b[1;32m-> 1015\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute 'base_dtype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190 samples, validate on 10 samples\n",
      "Epoch 1/5\n",
      "128/190 [===================>..........] - ETA: 0s - loss: 493308.5625 - acc: 0.4688\n",
      "Epoch 00001: val_loss improved from inf to 492898.25000, saving model to ./models/bayes_by_backprop.h5\n",
      "190/190 [==============================] - 2s 11ms/sample - loss: 493241.5862 - acc: 0.4632 - val_loss: 492898.2500 - val_acc: 0.6000\n",
      "Epoch 2/5\n",
      "128/190 [===================>..........] - ETA: 0s - loss: 492898.2500 - acc: 0.4609\n",
      "Epoch 00002: val_loss improved from 492898.25000 to 492488.81250, saving model to ./models/bayes_by_backprop.h5\n",
      "190/190 [==============================] - 1s 4ms/sample - loss: 492831.4164 - acc: 0.4789 - val_loss: 492488.8125 - val_acc: 0.3000\n",
      "Epoch 3/5\n",
      "128/190 [===================>..........] - ETA: 0s - loss: 492488.8125 - acc: 0.4609\n",
      "Epoch 00003: val_loss improved from 492488.81250 to 492080.21875, saving model to ./models/bayes_by_backprop.h5\n",
      "190/190 [==============================] - 1s 4ms/sample - loss: 492422.1217 - acc: 0.4737 - val_loss: 492080.2188 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "128/190 [===================>..........] - ETA: 0s - loss: 492080.2188 - acc: 0.4609\n",
      "Epoch 00004: val_loss improved from 492080.21875 to 491672.40625, saving model to ./models/bayes_by_backprop.h5\n",
      "190/190 [==============================] - 1s 4ms/sample - loss: 492013.6401 - acc: 0.4684 - val_loss: 491672.4062 - val_acc: 0.4000\n",
      "Epoch 5/5\n",
      "128/190 [===================>..........] - ETA: 0s - loss: 491672.4062 - acc: 0.4922\n",
      "Epoch 00005: val_loss improved from 491672.40625 to 491265.43750, saving model to ./models/bayes_by_backprop.h5\n",
      "190/190 [==============================] - 1s 4ms/sample - loss: 491605.9704 - acc: 0.4737 - val_loss: 491265.4375 - val_acc: 0.5000\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 491265.4375 - acc: 0.4900\n"
     ]
    }
   ],
   "source": [
    "#features = tf.Variable(x_train_padded[:5])\n",
    "#labels = tf.Variable(y_train[:5])\n",
    "#logits = model(features)\n",
    "\n",
    "#neg_log_likelihood = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "#    labels=labels, logits=logits)\n",
    "#kl = sum(model.losses)\n",
    "#loss = neg_log_likelihood + kl\n",
    "\n",
    "#optimizer =  tf.train.AdamOptimizer()\n",
    "\n",
    "#for epoch in range(epochs):\n",
    "#    train_op = optimizer.minimize(loss)\n",
    "#    print(train_op)\n",
    "\n",
    "\n",
    "# keras callbacks\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='logs') \n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(model_save_file, \n",
    "                                                      monitor='val_loss', \n",
    "                                                      verbose=1, \n",
    "                                                      save_best_only=True, \n",
    "                                                      save_weights_only=False, \n",
    "                                                      mode='auto')\n",
    "\n",
    "model.fit(x_train_padded, y_train, validation_split=0.05, epochs=epochs, batch_size=batch_size, callbacks=[tb_callback, model_checkpoint_cb])\n",
    "loss, accuracy = model.evaluate(x_train_padded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2697, 50)          4429400   \n",
      "_________________________________________________________________\n",
      "dense_flipout (DenseFlipout) (None, 2697, 512)         51712     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1380864)           0         \n",
      "_________________________________________________________________\n",
      "dense_flipout_1 (DenseFlipou (None, 1)                 2761729   \n",
      "=================================================================\n",
      "Total params: 7,242,841\n",
      "Trainable params: 2,813,441\n",
      "Non-trainable params: 4,429,400\n",
      "_________________________________________________________________\n",
      "(1, 1) (1,) (1, 2697)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.nn' has no attribute 'softmax_cross_entropy_with_logits_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-679a02d353ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m neg_log_likelihood = tf.nn.softmax_cross_entropy_with_logits_v2(\n\u001b[0m\u001b[0;32m     26\u001b[0m     labels=labels, logits=logits)\n\u001b[0;32m     27\u001b[0m \u001b[0mkl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.nn' has no attribute 'softmax_cross_entropy_with_logits_v2'"
     ]
    }
   ],
   "source": [
    "# tests tf 1.13\n",
    "# https://www.tensorflow.org/beta/guide/effective_tf2\n",
    "# https://github.com/tensorflow/probability/issues/409\n",
    "embedding_layer = keras.layers.Embedding(len(word_index.index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    embedding_layer,\n",
    "    tfpl.DenseFlipout(512, activation=tf.nn.relu),\n",
    "    keras.layers.Flatten(),\n",
    "    tfpl.DenseFlipout(1),\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "features = tf.Variable(x_train_padded[0:1])\n",
    "labels = tf.Variable(y_train[0:1])\n",
    "logits = model(features)\n",
    "print(logits.shape, labels.shape, features.shape)\n",
    "\n",
    "\n",
    "neg_log_likelihood = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=labels, logits=logits)\n",
    "kl = sum(model.losses)\n",
    "loss = neg_log_likelihood + kl\n",
    "print(loss)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    C:\\Users\\Tom\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow_probability\\python\\layers\\dense_variational.py:176 call  *\n        outputs = self.activation(outputs)  # pylint: disable=not-callable\n    <ipython-input-12-fa3b2f1b8fd2>:11 posterior_mean_field  *\n        return tf.keras.Sequential([\n    C:\\Users\\Tom\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow_probability\\python\\layers\\variable_input.py:119 __init__\n        raise ValueError('Shape must be known statically.')\n\n    ValueError: Shape must be known statically.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0c0007c8cc12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m#tfpl.DenseFlipout(1),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseFlipout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposterior_mean_field\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior_trainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1380864\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m ])\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    109\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    191\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    661\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    C:\\Users\\Tom\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow_probability\\python\\layers\\dense_variational.py:176 call  *\n        outputs = self.activation(outputs)  # pylint: disable=not-callable\n    <ipython-input-12-fa3b2f1b8fd2>:11 posterior_mean_field  *\n        return tf.keras.Sequential([\n    C:\\Users\\Tom\\Anaconda3\\envs\\mltf2\\lib\\site-packages\\tensorflow_probability\\python\\layers\\variable_input.py:119 __init__\n        raise ValueError('Shape must be known statically.')\n\n    ValueError: Shape must be known statically.\n"
     ]
    }
   ],
   "source": [
    "#tests tf 2.0\n",
    "embedding_layer = keras.layers.Embedding(len(word_index.index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(  # pylint: disable=g-long-lambda\n",
    "            tfd.Normal(loc=t[..., :n],\n",
    "                       scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "        tfp.layers.DistributionLambda(\n",
    "            lambda t: tfd.Independent(tfd.Normal(loc=t, scale=1),  # pylint: disable=g-long-lambda\n",
    "                                      reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "#self.dense1 = tfp.layers.DenseVariational(100, posterior_mean_field, prior_trainable, activation=tf.nn.relu, kl_weight=1/training_size))\n",
    "#self.dense2 = tfp.layers.DenseFlipout(10, posterior_mean_field, prior_trainable, kl_weight=1/training_size))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    embedding_layer,\n",
    "    #tfpl.DenseFlipout(512, activation=tf.nn.relu),\n",
    "    tfp.layers.DenseFlipout(512, posterior_mean_field, prior_trainable),\n",
    "    keras.layers.Flatten(),\n",
    "    #tfpl.DenseFlipout(1),\n",
    "    tfp.layers.DenseFlipout(1, posterior_mean_field, prior_trainable, input_shape=(None, 1380864))\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(inputs, training=True)\n",
    "        neg_log_likelihood = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits)\n",
    "        kl = sum(model.losses)\n",
    "        loss = neg_log_likelihood + kl\n",
    "    \n",
    "    _grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(_grad, model.trainable_variables))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(10):\n",
    "        feature = tf.expand_dims(x_train_padded[i], 0)\n",
    "        label = tf.expand_dims(y_train[i], 0)\n",
    "        train_step(feature, label)\n",
    "    print(\"Finished epoch\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.history\n",
    "\n",
    "if history:\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
